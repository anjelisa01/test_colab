{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXti3wm1F4YVxjI3Ipm8CW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anjelisa01/test_colab/blob/main/test1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmgqT1T1Fwqa",
        "outputId": "131e150c-1b0b-4ac8-e396-533c19c7e4fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'test_colab'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n",
            "/content/test_colab\n"
          ]
        }
      ],
      "source": [
        "# Replace TOKEN and USERNAME\n",
        "token = \"\"  # your GitHub token\n",
        "username = \"anjelisa01\"\n",
        "repo = \"test_colab\"\n",
        "\n",
        "!git clone https://{username}:{token}@github.com/{username}/{repo}.git\n",
        "%cd {repo}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kalo repo public bisa abis clone repo bisa langsung push via google colab 'save copy to github'"
      ],
      "metadata": {
        "id": "WDRYHpmOGlfe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "folder yang digenerate mlflow jangan dipush di github karena terlau auto-generate dan bisa terlau besar"
      ],
      "metadata": {
        "id": "bRFuwaIdIOPF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mlflow basically record version of the models but doesnt sync the way code versioning does like in git. jadi dalam satu notebook kita bisa run banyak versi dari model kita dan dengan mlflow secara otomatis direcord parameter dan result dari tiap versi yang kemudian disimpan di local folder 'mlruns', yang mana folder dan isinya di autogenerate setiap kita run codenya, hasilnya juga bisa kita simpan locally, dan bisa kita lihat menggunakan dashboar mlflow untuk dicompare dan sebagainya."
      ],
      "metadata": {
        "id": "W4ca2oMlJX1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ML and tracking tools\n",
        "!pip install -q scikit-learn pandas matplotlib seaborn\n",
        "!pip install -q mlflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdtw5n7UGFwm",
        "outputId": "0ea6577a-ea4a-43eb-f06d-c4cf4f95ba0a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.2/28.2 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.9/231.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m684.0/684.0 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "\n",
        "# Load dataset\n",
        "data = fetch_california_housing(as_frame=True)\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Create pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('model', RandomForestRegressor())\n",
        "])\n",
        "\n",
        "# Hyperparameter grid\n",
        "param_grid = {\n",
        "    'model__n_estimators': [10, 50, 100],\n",
        "    'model__max_depth': [5, 10, 20]\n",
        "}\n",
        "\n",
        "# Set up MLflow experiment\n",
        "mlflow.set_experiment(\"rf-hyperparameter-tuning\")\n",
        "\n",
        "# Grid search with CV\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
        "\n",
        "with mlflow.start_run():\n",
        "    grid.fit(X_train, y_train)\n",
        "\n",
        "    # Log best params & metrics\n",
        "    best_params = grid.best_params_\n",
        "    best_score = -grid.best_score_\n",
        "\n",
        "    mlflow.log_params(best_params)\n",
        "    mlflow.log_metric(\"best_mse\", best_score)\n",
        "\n",
        "    # Log best model\n",
        "    mlflow.sklearn.log_model(grid.best_estimator_, \"best_model\")\n",
        "\n",
        "    print(\"Best Params:\", best_params)\n",
        "    print(\"Best MSE:\", best_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Azp60BMeHS3U",
        "outputId": "e4bad7e4-b2c6-4e45-8d7a-dd27631ab9b7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/04/11 17:33:43 INFO mlflow.tracking.fluent: Experiment with name 'rf-hyperparameter-tuning' does not exist. Creating a new experiment.\n",
            "\u001b[31m2025/04/11 17:37:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Params: {'model__max_depth': 20, 'model__n_estimators': 100}\n",
            "Best MSE: 0.25775673175690417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat mlruns/876423425175477713/3fc752332df24e4eabdff113068f3dbc/metrics/best_mse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGunS7v4TL23",
        "outputId": "c149a65b-4cdf-45a6-bddb-e884b0bedd13"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1744393056726 0.25775673175690417 0\n"
          ]
        }
      ]
    }
  ]
}